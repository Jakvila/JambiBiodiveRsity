---
title: "panel_data_script"
output: pdf_document
---

## About p-values
Unsignificant values don't permit us to draw the conclusion that there is no real effect.
Looking at papers in detail is like looking at the backyard of a slaughterhouse.
Only the p-value is almost never sufficient to draw meaningful conclusions on significance of a coefficient. At least we should take the effect size into account.

### Panel data

Repeated observations of some individual unit over time.
standard case: The same individual over the same unit of time. -> balanced panel

But "atrition" often leads to unbalanced panels. 
Notation: Notation for subscript

i : index for individual observations

t : index for time periods



$ X_i,t , ... $

if N individuals for T time periods => sample size
NT: balanced panel

everything else: unbalanced people

Further examples:

Rotationg panels (Socio-Economic panel SOEP)

Pseudo panels ( mean cohort values over time): often used for poverty research in developing countries. Advantage: can combine data, once the cohort is identified. Deaton (1985)

Why panel data?
\begin{itemize}
\item{ more observations => more information}
\item{dynamic analysis: \item{shocks over time average out}}
\item{ \textbf{unobserved heterogeneity}}
\end{itemize}
\section{Notation:}

Linear Regression 

cross section $ Y_i = \beta_0 + \beta_1*X_1i + u_i ... $

panel structure $ Y_{it} = \beta_0 + \beta_1*X_{1it} + u{it} ... $

  $ Y_{it} = \beta_{0t} +  \beta_1*X_{1it} + u{it} ... $
                
t = 1 $ Y_{i1} = \beta_{01} + \beta_1*X_{1,1} + u_{i1} ... $
                
 t = T $ Y_{iT} = \beta_{0T} + \beta_{1T}*X_{1iT} + u_{iT} ... $
                
                
                
$ D_{i} = 1 if i = j,  D_{i} = 0 if i != j for j = 1,..., N $
                
least-squares dummy variable estimator LSDV 
with individual means over time.
                
                
 $ (Y_{it} - \bar Y_{i0}) = \beta_1(X_{it}-x_{1i.}) + (u_{it} - \bar u_i) $
               
 how to get $ \hat \beta_{0i} $ ?
$ \hat \beta_{0i} = \bar Y_{i0} - \beta $
                
                
                
```{r warning=FALSE}
                
   library(plm)
                
   setwd("C:/Users/jakob/OneDrive/University/Data_analysis_Oct19/Panel_data")
dataNL <- readRDS("dataNL.rds")
   names(dataNL) <-   c("index", "year", "milk", "other", "x1", "x2", "x3", "x4", "x5", "trend")
                
  summary(dataNL)          
                
  dataNL$lmilk <- -log(-dataNL$milk)
  dataNL$lx1 <- log(dataNL$x1)
  dataNL$lx2 <- log(dataNL$x2)
  dataNL$lx3 <- log(dataNL$x3)
  dataNL$lx4 <- log(dataNL$x4)
  dataNL$lx5 <- log(dataNL$x5)
```

            
  
            The trend variable remains unlogged.
            
```{r panel2}
            plot(dataNL$lmilk~dataNL$lx1)
            plot(dataNL$lmilk~dataNL$lx2)
            plot(dataNL$lmilk~dataNL$lx3)
            plot(dataNL$lmilk~dataNL$lx4)
            plot(dataNL$lmilk~dataNL$lx5)

            formula.NL <- lmilk ~ lx1 + lx2 + lx3 + lx4 + lx5 + trend
            
            lm.NL <- lm(formula.NL , data=dataNL)
                
                summary(lm.NL)
                
            Pool.NL <- plm(formula.NL, data = dataNL, model = "pooling")
            
            summary(Pool.NL)
            
            formula.LSDV <- lmilk ~ lx1 + lx2 + lx3 + lx4 + lx5 + trend + as.factor(index) # if we run that , index has ~ 140 dummy variables we run into the problem of perfect multicollinearity. So R automatically drops one of the dummies.
            
            lm.LSDV <- lm(formula.LSDV, data = dataNL)
      
            summary((lm.LSDV))
         
```
            In order to extract a coefficient, we use the coef() function
```{r panel3}
            
coef(Pool.NL)[2:6]
sum(coef(Pool.NL)[2:6])
              
```
                output at 1.06 which is too high. Maybe we get different results with the LSDV estimator.
  
            
  coef(lm.LSDV)[2:6]
   sum(coef(lm.LSDV)[2:6])
              

  now lower coefficient taking the index dummies into account.
              
```{r panel4}
            
require(car)
              
linearHypothesis(Pool.NL , "lx1+lx2+lx3+lx4+lx5=1")
              
summary(Pool.NL)
summary(lm(formula.NL, data = dataNL))
sum(coef(Pool.NL)[2:6])
              
WI.NL <- plm(formula.NL, data = dataNL, model = "within")
cbind(coef(lm.LSDV[2:7], coef(WI.NL)))
              
```
                About manually applying F-Tests :
                 - unrestricted (ignoring H0) - RSS^UR [residual sum of squares]
                 restricted( imposing H0) - RSS^R
                 
                 \[ \star F = \frac {RSS^R - RSS^UR / +1}{RSS^UR / (NT - (k-1))} \]
                 
                 
  Substract means from every variable.. Using loops (?)
              
Dummy variables you cannot meaningfully de-mean over time. So we use the LM, but should get out the same                results as with the LSDV model.
```{r panel5}
  # wi2.NL <- plm(formula.NL, data = dataNL, effect = "twoways", model = "within )
  plot(density(fixef(WI.NL)))
              
```
          Problem: time-invariant variables and how to deal with them..
```{r panel6}
dataNL$TimeInvar <- runif(141) %x% rep(1, 4)
formula.TimeInvar <- dataNL$lmilk + dataNL$lx1 + dataNL$lx2 + dataNL$lx3 + dataNL$lx4 + dataNL$lx5 + dataNL$trend + dataNL$TimeInvar
              
              
head(dataNL$TimeInvar)  
WI.NL <- plm(formula.NL , data = dataNL, model = "within")
                
```
                Next steps: random effects model
                
## scenario
                
                No interest in the unobserved heterogeneity, no need to interpret the individual effects;
                 
\[ \alpha_i \] - parameters are a mere cuisance (guidance?) --> error
                  
\[ Y_{i,t} = \alpha_i + \beta_1*X_{1,i,t} + u_{i,t} \]
alpha is error 
\[ = \beta_0 + \beta_1X_{1,i,t} + \alpha_i +  u_{i,t} \]
                  
two error components alpha_i, u_it
                  
Ignore error structure: OLS \rightarrow unbiased
  \rightarrow inefficient
                  
\[ \alpha_i ~ N(0, \sigma_\alpha^2)  with u_{it} ~ N(0, \sigma_u^2)\]
                  
 Estimating: Feasible Generalised Least Squares FGLS
                  
\[ E(Cov[X, u]) = 0 \]
  \[ E(Cov[X, \alpha]) = 0 \] \leftarrow in many contexts this is a critical assumption
  It is often questionable that individual effects and regressors are uncorrelated.
  This is NOT required in a fixed-effects model. 
                 
                 
\Rightarrow Wald test:
                 
 \[ (\beta_{FE} - \beta_{RE})(\hat VCOV_{FE} - \hat VCOV_{RE})^(-1)*(\beta_{FE} - \beta_{RE}) \] 
               
$\Rightarrow$ Hausmann Test:
 Alternative: Variable addition
                  
FE by within  
                
                
 2) plus all X bar i $\Rightarrow$ should be not having any expl power if $E(cov(x, \alpha))$ = 0
                
Test by F-test whether all $\[ \bar X_{i, s} \]$ have zero parameters or not. 
                
"Mundlak correction"
                

```{r panel7}
                
                RE.NL <- plm(formula.NL, data=dataNL, model = "random")
                cbind(coef(WI.NL), coef(Pool.NL)[2:7])
                
                cbind(coef(WI.NL), coef(Pool.NL)[2:7], coef(RE.NL)[2:7])
                
                summary(RE.NL)
                
                
                phtest(formula.NL, data = dataNL)
                
                
                qchisq(0.95, 6)
                
                mP <- diag(141) %x% crossprod(t(rep(1,4)), rep(1,4))
```
                
 We got a lower R²
                
                
Conclusion by chi² test: RE model is inconsistent, we should be using the fixed effects model. 
Time specific means as result of cronica product are added to the RE model. 

```{r panel8}








            formula.VarAdd <- lmilk~lx1+lx2+lx3+lx4+lx5+trend+lx1M+lx2M+lx3M+lx4M+lx5M
RE.VarAdd <- plm(formula.VarAdd, data=dataNL, method = "random")
RE.VarAdd <- plm(formula.VarAdd, matchCoefs(RE.VarAdd, "M"))
pooltest(Pool.NL, WI.NL)
pwartest(WI.NL)

library(lmtest)
summary(WI.NL)


```

Further panel tests

1) poolability: e.g. Pooling model against FE panel

more general: 
 $ Y_{it} = \beta_{0i/t} +  \beta_{1i/t}*X_{1it} + u_{it} ... $
 
 e.g.$ H_0 : \beta_{1i} = \beta_{1}$
      
$ H_1 : \beta_{1i} \ne \beta_{1}$

Pooling testing with switching coefficients as un-restricted model & FE as restricted $\Rightarrow$ F-Test


2) Heteroskedasticity, i.e. Cross-sectional dependence 

 HSK $\rightarrow$ efficiency loss
 
 Diagnosis 
 
 - formal tests: White-Test, Breusch-Pagan test

if HSK is detected
a) weighted least squares
b) robust standard errors


heteroskedasticity consistent S.E.
\textbf{HCSE}

```{r panel9}

library(lmtest)

summary(WI.NL)
pcdtest(WI.NL)

coeftest(WI.NL, vcovBK, df=418)
coeftest(WI.NL, vcovBK(WI.NL, method = "arellano", type = "HC4"), df=418)

summary(RE.NL)
phtest(WI.NL, RE.NL, vcov=vcovHC) # hausman

coeftest(WI.NL, vcovHAC, df=418)
coeftest(WI.NL, vcovHC(WI.NL, method = "arellano", type = "HC4"), df=418)

```
  
 #### Two-way effects
  
  individual and \textdf{temporal} heterogeneity
  
  #### one-way FE:
  
  $ Y_{it} : \alpha_{i} + \lambda_t +  \beta_{1}X_{1it} + u_{it}$
  
  FE: Dummy vars for $N$ observations plus dummies for $T$ time periods
  
  First differences: wipes out $\alpha_i$'s and absorbs the $\lambda_t$s in a constant
  
  Estimation by RE: + $\lambda_t ~ N(0,\sigma^2)$
  
  
```{r panel10}

formula.NOTrend <- update(formula.NL, ~ . -trend)
formula.NOTrend
FE.2ways <- plm(formula.NOTrend, data = dataNL, model = "within", effect = "twoways")

summary(FE.2ways)
phtest(form.NL, data = dataNL)



coef(WI.NL)

fixef(FE.2ways, effect = "time")
diff(fixef(FE.2ways, effect = "time"))
mean(diff(fixef(FE.2ways, effect = "time")))*100

```
```{r panel11}
formula.Trend <- update(formula.NL, ~ .)
formula.Trend

RE.2ways <- plm(formula.Trend, data = dataNL, model = "random", effect = "twoways", random.method = "amemiya")

summary(RE.2ways)
phtest(form.NL, data = dataNL)



coef(WI.NL)

fixef(FE.2ways, effect = "time")
diff(fixef(FE.2ways, effect = "time"))
mean(diff(fixef(FE.2ways, effect = "time")))*100

```
  
  
  
  
                